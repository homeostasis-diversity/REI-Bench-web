<!DOCTYPE html>
<html lang="en">
<!-- 网页设定 -->

<head>
  <!-- 网页基础信息设置 -->
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>REI-Bench: Vague Instructions in Task Planning</title>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
  <script src="https://unpkg.com/diff-match-patch@1.0.5/index.js"></script>

  <!-- 页面样式定义 -->
  <style>
    /* 整体页面字体、行距、背景颜色和内边距设置 */
    body {
      font-family: 'Roboto', sans-serif;
      background: white;
      margin: 0;
      padding: 40px;
      text-align: left;
      color: #333;
    }

    /* 标题样式：颜色和居中 */
    h1 {
      font-size: 2.5em;
      background: linear-gradient(to right, #f97316, #22c55e, #3b82f6);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      margin-bottom: 0.3em;
      text-align: center;
    }

    /* 标题样式 */
    h1 span {
      color: #f97316;
      text-align: center;
    }

    h2 {
      margin-top: 60px;
      font-size: 1.6em;
      color: #222;
      text-align: left;
    }

    h2.abstract-heading {
      text-align: center;
      text-align: center;
    }

    h3 {
      margin-top: 30px;
      font-size: 1.3em;
      color: #333;
      text-align: left;
    }

    /* 正文样式-默认 */
    .text-default {
      font-size: 1.05em;
      text-align: justify;
    }

    .text-abstract {
      font-size: 1.05em;
      text-align: justify;
      max-width: 70%;
      margin: 0 auto; /* 居中 */
      color: #444;
    }


    /* 作者信息样式 */
    .authors {
      font-size: 1.3em;
      margin: 15px 0;
      text-align: center;
    }

    .authors a {
      color: #2c7edb;
      text-decoration: none;
      margin: 0 15px;
      text-align: center;
    }

    .affiliation {
      color: #0a0a0a;
      margin-top: 15px;
      font-size: 1.3em;
      text-align: center;
    }

    .lab-link {
      font-weight: bold;
      background: linear-gradient(90deg, #ef4444, #f59e0b, #facc15); /* 红 -> 橙 -> 黄 */
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      text-decoration: none;
      margin-top: 15px;
      font-size: 1.3em;
      text-align: center;
    }

    .lab-link:hover {
      text-decoration: underline;
      margin-top: 15px;
      font-size: 1.3em;
      text-align: center;
    }


    .email {
      margin-top: 13px;
      font-size: 1.3em;
      text-align: center;
    }

    /* 个人页面等跳转按钮设计 */
    .buttons {
      margin-top: 25px;
      text-align: center;
    }

    .buttons a {
      display: inline-block;
      background: #1f2937;
      color: white;
      padding: 10px 18px;
      border-radius: 30px;
      margin: 8px;
      text-decoration: none;
      font-weight: bold;
      transition: background 0.3s ease;
    }

    .buttons a:hover {
      background: #4b5563;
    }

    .footer {
      margin-top: 40px;
      font-size: 1.1em;
      color: #555;
    }

    /* 头图样式 */
    img {
      width: 100%;
      max-width: 100%;
      height: auto;
      display: block;
      margin-top: 20px;
    }

    /* 页面主容器样式：宽度、居中、白色背景、内边距、圆角 */
    .container {
      max-width: 900px;
      margin: auto;
      background: white;
      padding: 20px;
      border-radius: 8px;
    }

    /* 表格样式：宽度、边框、间距 */
    table {
      width: 100%;
      border-collapse: collapse;
      margin-top: 20px;
    }

    /* 表格内容样式：边框、内边距、左对齐 */
    th, td {
      border: 1px solid #ddd;
      padding: 10px;
      text-align: left;
    }

    /* 表头背景色 */
    th {
      background-color: #f2f2f2;
    }

    /* iframe 视频展示区域样式 */
    iframe {
      width: 100%;
      height: 400px;
      margin-top: 20px;
      border: none;
    }

    .image-display {
      display: flex;
      justify-content: center;
      gap: 40px;
      margin-bottom: 30px;
    }

    /* === 按钮 === */
    button {
      display: inline-block;
      padding: 10px 22px;
      font-size: 15px;
      font-weight: 500;
      border: none;
      border-radius: 8px;
      background: linear-gradient(90deg,#ff7b7b,#ff5064); /* 渐变 */
      color: #fff;
      cursor: pointer;
      transition: transform .15s ease, box-shadow .15s ease;
    }
    button:hover {
      transform: translateY(-2px);
      box-shadow: 0 4px 8px rgba(0,0,0,.15);
    }
    button:active {
      transform: translateY(0);
      box-shadow: 0 2px 4px rgba(0,0,0,.2);
    }

    /* 可互动图片展示区域样式 */
    .image-display {
      display: flex;
      justify-content: center;
      gap: 3rem;
      flex-wrap: wrap;
      margin-bottom: 2rem;
    }

    .image-display img {
      max-width: 90%;
      width: 500px;
      height: auto;
      border-radius: 1rem;
      box-shadow: 0 6px 20px rgba(0,0,0,0.1);
      transition: transform 0.3s ease;
    }

    .image-display img:hover {
      transform: scale(1.02);
    }

    .image-display-prompting img {
      width: 70%;          /* 宽度占父容器70% */
      max-width: 500px;    /* 最大不超过500px */
      height: auto;        /* 高度自适应 */
      border-radius: 1rem;
      box-shadow: 0 6px 20px rgba(0,0,0,0.1);
      transition: transform 0.3s ease;
    }

    .image-display-prompting img:hover {
      transform: scale(1.02);
    }

    .selector {
      display: flex;
      justify-content: center;
      gap: 3rem;
      flex-wrap: wrap;
    }

    .selector div {
      background: #fff;
      padding: 1rem 1.5rem;
      border-radius: 1rem;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);
      transition: box-shadow 0.3s ease;
    }

    .selector div:hover {
      box-shadow: 0 6px 20px rgba(0, 0, 0, 0.12);
    }

    label {
      font-weight: bold;
      display: block;
      margin-bottom: 0.5rem;
      font-size: 1rem;
    }

    select {
      font-size: 1rem;
      padding: 0.5rem;
      border-radius: 0.5rem;
      border: 1px solid #ccc;
      width: 100%;
    }

    /* 文本变异控件 */
    .box-container {
      display: flex;
      flex-direction: column;
      gap: 1.5rem;
      width: 100%;
      /* max-width: 1000px; */
      margin: 0 auto; /* ✅ 水平居中 */
      padding: 0 1rem; /* ✅ 页面左右留白 */
    }

    .chat-wrapper {
      display: flex;
      align-items: flex-start;
      gap: 0.8rem;
    }

    .chat-wrapper.human {
      flex-direction: row;
      justify-content: flex-start;
    }

    .chat-wrapper.robot {
      flex-direction: row-reverse;
      justify-content: flex-end;
    }

    .avatar {
      width: 40px;
      height: 40px;
      border-radius: 50%;
      background-size: cover;
      background-position: center;
      flex-shrink: 0;
    }

    .avatar.human {
      background-image: url('media/human_icon.png');
      background-size: cover;
      width: 40px;
      height: 40px;
      border-radius: 10%;
    }

    .avatar.robot {
      background-image: url('media/robot_icon.png');
      background-size: cover;
      width: 40px;
      height: 40px;
      border-radius: 10%;
    }

    .text-box {
      background: #f9f9f9;
      padding: 14px 18px;
      border-radius: 16px;
      /* max-width: 70%; */
      font-size: 14px;
      line-height: 1.5;
      box-shadow: 0 2px 6px rgba(0,0,0,0.05);
      font-family: sans-serif;
    }


    .main-button {
      margin-top: 2rem;
      padding: 0.7rem 1.5rem;
      font-size: 1rem;
      background-color: #4CAF50;
      border: none;
      border-radius: 6px;
      color: white;
      cursor: pointer;
    }

    .main-button:disabled {
      background-color: #aaa;
      cursor: not-allowed;
    }

    .orange {
      color: orange;
      font-weight: bold;
    }

    .red {
      color: red;
      font-weight: bold;
    }

    .blue-strike {
      color: blue;
      text-decoration: line-through;
    }
  </style>
</head>

<body>
  <!-- 页面主体容器 -->
  <div class="container">

    <!-- 页面主标题 -->
    <h1><span>REI-Bench</span>: Can Embodied Agents Understand Vague Human Instructions in Task Planning?</h1>

    <!-- 作者信息区 -->
    <div class="authors">
      <a href="#">Chenxi Jiang, Chuhao Zhou, Jianfei Yang</a>
    </div>
    <div class="affiliation">
      <a class="lab-link" href="https://marslab.tech/" target="_blank">MARS Lab</a>, Nanyang Technological University
    </div>
    <div class="email">{CHENXI003, chuhao002, jianfei.yang}@ntu.edu.sg</div>


    <!-- 个人链接跳转按钮 -->
    <div class="buttons">
        <a href="https://github.com/homeostasis-diversity/RIE-Bench" target="_blank" rel="noopener noreferrer">Code</a>
        <a href="https://arxiv.org/pdf/2505.10872" target="_blank" rel="noopener noreferrer">Paper</a>
        <a href="https://arxiv.org/abs/2505.10872" target="_blank" rel="noopener noreferrer">arXiv</a>
        <a href="#bibtex" target="_blank" rel="noopener noreferrer">BibTeX</a>
    </div>

    <!-- <div class="footer">
        Under review at CoRL 2025
    </div> -->

    <!-- teaser区域 -->
    <img src="media\figure1_teaser_motivation.png" alt="Teaser Image" />

    <section style="margin-top: 40px;">
      <h2 class="abstract-heading">Abstract</h2>
      <p class="text-abstract">
        Robot task planning decomposes human instructions into executable action sequences that enable robots to complete a series of complex tasks. 
        Although recent large language model (LLM)-based task planners achieve amazing performance, 
        they assume that human instructions are clear and straightforward. 
        However, real-world users are not experts, and their instructions to robots often contain significant vagueness. 
        Linguists suggest that such vagueness frequently arises from referring expressions (REs), 
        whose meanings depend heavily on dialogue context and environment. 
        This vagueness is even more prevalent among the elderly and children, who robots should serve more. 
        This paper studies how such vagueness in REs within human instructions affects LLM-based robot task planning and how to overcome this issue. 
        To this end, we propose the first robot task planning benchmark with vague REs (REI-Bench), 
        where we discover that the vagueness of REs can severely degrade robot planning performance, 
        leading to success rate drops of up to 77.9%. We also observe that most failure cases stem from missing objects in planners. 
        To mitigate the REs issue, we propose a simple yet effective approach: task-oriented context cognition,
         which generates clear instructions for robots, achieving state-of-the-art performance compared to aware prompt and chains of thought. 
         This work contributes to the research community of human-robot interaction (HRI) by making robot task planning more practical, 
         particularly for non-expert users, e.g., the elderly and children.
      </p>
    </section>

    <!-- 视频区域 -->
    <h2>Motivation</h2>
    <p class="text-default">
        Recent advancements in large language models (LLMs) have significantly improved robots’ ability to follow natural language instructions. 
        However, a key limitation remains: most existing systems operate under the assumption that human instructions are always clear and explicit. 
        In practice, human language is often underspecified. 
        Speakers frequently use referentially vague expressions—such as "it" or "that heavy thing"—with the expectation that the listener will infer 
        the intended meaning from context. While humans are adept at resolving such ambiguity, robots continue to struggle, particularly in complex 
        real-world environments like kitchens, where misinterpretations can lead to task failure. This phenomenon, known as coreferential vagueness, 
        arises when an object is referenced without being explicitly named. For instance, a command like “Move it” may refer to a pot, a plate, or 
        any other nearby item, depending on contextual cues. Although humans rely on memory and situational awareness to resolve these expressions, 
        LLM-based robotic planners often lack the capability to do so reliably.
    </p>

    <!-- 本地视频播放 -->
    <video width="900" height="500" controls>
        <source src="media/video.mp4" type="video/mp4">
        Your browser does not support the video tag.
    </video>


    <!-- 研究内容介绍 -->
    <h2>Method</h2>
    <p class="text-default">
      The objective of our work is to comprehensively evaluate and analyze how different levels of coreferential 
      vagueness from implicit referring expressions affect the planner's performance across diverse multi-turn dialogue contexts. 
      To this end, we first systematically formalize eferring expressions in an HRI context, then establish the REI dataset and benchmark to 
      evaluate planners in embodied tasks involving vague instructions, and finally introduce a simple yet effective solution.
    </p>
    <img src="media\figure2_method.png" alt="Teaser Image" />

    <h3 style="text-align: left;">Human-Robot Interaction: from Clarity to Vagueness</h3>
    <!-- 文本变异展示2 -->
    <div class="box-container" id="boxContainer"></div>
    <button class="main-button" id="mainBtn" disabled>Introduce Vagueness</button>

    <script>
      const stages = [
        [
          `<span class="role-indicator" style="display:none">class="human"</span>
          Hey there, I've been thinking about what to do with <span class="orange">the tomatoes</span> we have. 
          I really want to make something fresh and delicious with them. 
          Can you remind me what we can do with <span class="orange">tomatoes</span>?`,
          `<span class="role-indicator" style="display:none">class="robot"</span>
          Absolutely, Alice! <span class="orange">Tomatoes</span> can be used in a variety of dishes, 
          like sauces, soups, or even as a topping for salads. They enhance flavors and add a nice texture to the meal.`,
          `<span class="role-indicator" style="display:none">class="human"</span>
          That's exactly what I was thinking! 
          I could use <span class="orange">tomatoes</span> to create a savory sauce for pasta or maybe even a comforting soup. 
          Do we have everything we need to cook <span class="orange">tomatoes</span>, though?`,
          `<span class="role-indicator" style="display:none">class="robot"</span>
          Let me check our supplies. We have a pot for cooking, some spices like salt and pepper, 
          and a cutting board. We seem to be well-equipped for cooking <span class="orange">tomatoes</span> to perfection.`,
          `<span class="role-indicator" style="display:none">class="human"</span>
          Perfect! I want to make sure they're well-seasoned when we cook <span class="orange">tomatoes</span>. 
          Could you remind me how to properly prepare <span class="orange">tomatoes</span> before cooking?`,
          `<span class="role-indicator" style="display:none">class="robot"</span>
          Certainly! First, we should wash <span class="orange">them</span> thoroughly, 
          then chop <span class="orange">tomatoes</span> into even pieces to ensure they cook evenly. After that, 
          we can sauté <span class="orange">tomatoes</span> with the spices until they reach the desired consistency.`,
          `<span class="role-indicator" style="display:none">class="human"</span>
          Great, that sounds easy enough! Let's get started with cooking <span class="red">tomatoes</span>. 
          Once they're cooked and ready, I'll need you to put <span class="red">them</span> in the refrigerator.`
        ],
        [
          `<span class="role-indicator" style="display:none">class="human"</span>
          Hey there, I've been thinking about what to do with <span class="orange">the tomatoes</span> we have. 
          I really want to make something fresh and delicious with them. 
          Can you remind me what we can do with <span class="orange">them</span>?`,
          `<span class="role-indicator" style="display:none">class="robot"</span>
          Absolutely, Alice! <span class="orange">Tomatoes</span> can be used in a variety of dishes, 
          like sauces, soups, or even as a topping for salads. They enhance flavors and add a nice texture to the meal.`,
          `<span class="role-indicator" style="display:none">class="human"</span>
          That's exactly what I was thinking! 
          I could use <span class="orange">them</span> to create a savory sauce for pasta or maybe even a comforting soup. 
          Do we have everything we need to cook <span class="orange">them</span>, though?`,
          `<span class="role-indicator" style="display:none">class="robot"</span>
          Let me check our supplies. We have a pot for cooking, some spices like salt and pepper, 
          and a cutting board. We seem to be well-equipped for cooking <span class="orange">tomatoes</span> to perfection.`,
          `<span class="role-indicator" style="display:none">class="human"</span>
          Perfect! I want to make sure they're well-seasoned when we cook <span class="orange">them</span>. 
          Could you remind me how to properly prepare <span class="orange">the fruit</span> before cooking?`,
          `<span class="role-indicator" style="display:none">class="robot"</span>
          Certainly! First, we should wash <span class="orange">them</span> thoroughly, 
          then chop <span class="orange">tomatoes</span> into even pieces to ensure they cook evenly. After that, 
          we can sauté <span class="orange">tomatoes</span> with the spices until they reach the desired consistency.`,
          `<span class="role-indicator" style="display:none">class="human"</span>
          Great, that sounds easy enough! Let's get started with cooking <span class="red">the fruit</span>. 
          Once they're cooked and ready, I'll need you to put <span class="red">them</span> in the refrigerator.`
        ],
        [
          `<span class="role-indicator" style="display:none">class="human"</span>
          Hey there, I've been thinking about what to do with <span class="orange">the tomatoes</span> we have. 
          I really want to make something fresh and delicious with them. 
          Can you remind me what we can do with <span class="orange">them</span>?`,
          `<span class="role-indicator" style="display:none">class="robot"</span>
          Absolutely, Alice! <span class="orange">Tomatoes</span> can be used in a variety of dishes, 
          like sauces, soups, or even as a topping for salads. They enhance flavors and add a nice texture to the meal.`,
          `<span class="role-indicator" style="display:none">class="human"</span>
          That's exactly what I was thinking! 
          I could use <span class="orange">them</span> to create a savory sauce for pasta or maybe even a comforting soup. 
          <span class="red">I know Mug Star would love to help with that!</span> Do we have everything we need to cook the tomatoes, though?</span>`,
          `<span class="role-indicator" style="display:none">class="robot"</span>
          Let me check our supplies. We have a pot for cooking, some spices like salt and pepper, 
          and a cutting board. We seem to be well-equipped for cooking <span class="orange">tomatoes</span> to perfection.`,
          `<span class="role-indicator" style="display:none">class="human"</span>
          Perfect! I want to make sure they're well-seasoned when we cook <span class="orange">them</span>. 
          </span> <span class="red">I bet Mug Star would add his own twist with some cheesy jokes while we cook.</span> 
          Could you remind me how to properly prepare <span class="orange">the fruit</span> before cooking?`,
          `<span class="role-indicator" style="display:none">class="robot"</span>
          Certainly! First, we should wash <span class="orange">them</span> thoroughly, 
          then chop <span class="orange">tomatoes</span> into even pieces to ensure they cook evenly. After that, 
          we can sauté <span class="orange">tomatoes</span> with the spices until they reach the desired consistency.`,
          `<span class="role-indicator" style="display:none">class="human"</span>
          Great, that sounds easy enough! Let's get started with cooking <span class="red">the fruit</span>. 
          Once they're cooked and ready, I'll need you to put <span class="red">them</span> in the refrigerator.
          <span class="red">I can already imagine Mug Star popping in with a funny quip about how tomatoes are technically a fruit!</span>`
        ],
        [
          `<span class="role-indicator" style="display:none">class="human"</span>
          Hey there, I've been thinking about what to do with <span class="orange">the tomatoes</span> we have. 
          <span class="blue-strike">I really want to make something fresh and delicious with them. 
          Can you remind me what we can do with <span class="orange">them</span>?</span>`,
          `<span class="role-indicator" style="display:none">class="robot"</span>
          Absolutely, Alice! <span class="orange">Tomatoes</span> can be used in a variety of dishes, 
          like sauces, soups, or even as a topping for salads. They enhance flavors and add a nice texture to the meal.`,
          `<span class="role-indicator" style="display:none">class="human"</span>
          That's exactly what I was thinking! 
          I could use <span class="orange">them</span> to create a savory sauce for pasta or maybe even a comforting soup. 
          <span class="red">I know Mug Star would love to help with that!</span> 
          <span class="blue-strike">Do we have everything we need to cook the tomatoes, though?</span>`,
          `<span class="role-indicator" style="display:none">class="robot"</span>
          Let me check our supplies. We have a pot for cooking, some spices like salt and pepper, 
          and a cutting board. We seem to be well-equipped for cooking <span class="orange">tomatoes</span> to perfection.`,
          `<span class="role-indicator" style="display:none">class="human"</span>
          <span class="blue-strike">Perfect! I want to make sure they're well-seasoned when we cook <span class="orange">them</span></span> . 
          </span> <span class="red">I bet Mug Star would add his own twist with some cheesy jokes while we cook.</span> 
          Could you remind me how to properly prepare <span class="orange">the fruit</span> before cooking?`,
          `<span class="role-indicator" style="display:none">class="robot"</span>
          Certainly! First, we should wash <span class="orange">them</span> thoroughly, 
          then chop <span class="orange">tomatoes</span> into even pieces to ensure they cook evenly. After that, 
          we can sauté <span class="orange">tomatoes</span> with the spices until they reach the desired consistency.`,
          `<span class="role-indicator" style="display:none">class="human"</span>
          Great, that sounds easy enough! Let's get started with cooking <span class="red">the fruit</span>. 
          Once they're cooked and ready, I'll need you to put <span class="red">them</span> in the refrigerator.
          <span class="red">I can already imagine Mug Star popping in with a funny quip about how tomatoes are technically a fruit!</span>`
        ]
      ];
      const container = document.getElementById("boxContainer");
      const mainBtn = document.getElementById("mainBtn");
      const dmp = new diff_match_patch();
      const boxObjects = [];
      let currentStage = 0;

      function extractRole(html) {
        if (html.includes('class="human"')) return 'human';
        if (html.includes('class="robot"')) return 'robot';
        return 'human';
      }

      function wrapInChatBox(role, content) {
        const wrapper = document.createElement("div");
        wrapper.className = `chat-wrapper ${role}`;
        wrapper.innerHTML = `
          <div class="avatar ${role}" alt="Avatar of ${role} speaker"></div>
          <div class="text-box"></div>
        `;
        const box = wrapper.querySelector(".text-box");
        box.innerHTML = content;
        return { wrapper, box };
      }

      function createBox(stageIndex, boxIndex) {
        const rawText = stages[stageIndex][boxIndex];
        const role = extractRole(rawText);
        const { wrapper, box } = wrapInChatBox(role, "");

        container.appendChild(wrapper);
        let currentText = rawText;

        function typeInitial(callback) {
          let i = 0;
          function step() {
            if (i <= currentText.length) {
              box.innerHTML = currentText.slice(0, i);
              i++;
              setTimeout(step, 30);
            } else {
              callback();
            }
          }
          step();
        }

        function typeToNext(nextText, callback) {
          const diffs = dmp.diff_main(currentText, nextText);
          dmp.diff_cleanupSemantic(diffs);

          let i = 0;
          let charIndex = 0;
          let result = '';

          function step() {
            if (i >= diffs.length) {
              currentText = nextText;
              callback();
              return;
            }

            const [op, data] = diffs[i];

            if (op === 0) {
              // Equal: add whole chunk immediately
              result += data;
              box.innerHTML = result;
              i++;
              step();
            } else if (op === 1) {
              // Insert: type one char at a time
              if (charIndex < data.length) {
                result += data[charIndex];
                box.innerHTML = result;
                charIndex++;
                setTimeout(step, 30);
              } else {
                i++;
                charIndex = 0;
                step();
              }
            } else if (op === -1) {
              // Delete: skip; assume it's already struck out in HTML or handled semantically
              i++;
              step();
            }
          }

          step();
        }


        return {
          typeInitial,
          typeToNext
        };
      }

      (async () => {
        for (let i = 0; i < stages[0].length; i++) {
          const boxObj = createBox(0, i);
          boxObjects.push(boxObj);
          await new Promise(resolve => boxObj.typeInitial(resolve));
          await new Promise(r => setTimeout(r, 200));
        }
        mainBtn.disabled = false;
      })();

      mainBtn.onclick = async () => {
        mainBtn.disabled = true;
        const nextStage = (currentStage + 1) % stages.length;
        for (let i = 0; i < boxObjects.length; i++) {
          const nextText = stages[nextStage][i];
          await new Promise(resolve => boxObjects[i].typeToNext(nextText, resolve));
          await new Promise(r => setTimeout(r, 400));
        }
        currentStage = nextStage;
        mainBtn.disabled = false;
      };
    </script>

  
  <!-- 实验结果展示 -->
  <h2>Evaluations</h2>
  <h3 style="text-align: left;">Benchmark Result</h3>
  <p class="text-default">
    Existing LLM-based task planners struggle to handle instructions in multi-turn dialogues, 
    particularly when implicit referring expressions introduce vagueness. 
    In contrast, noise and partial context omission have less impact on their performance. 
    These challenges are common in real-world human-robot interactions and need to be addressed.
  </p>
  <!-- 主展示区 -->
  <div class="image-display" style="
      display: flex;
      justify-content: center;
      align-items: flex-start;
      gap: 40px;
      flex-wrap: nowrap;
  ">
      <div style="width: 500px; text-align: center;">
          <img id="imgLeft" src="media/success-rate-heatmap_Model__LLaMA3.1-8B__Framework__SayCan.jpg" width="100%">
          <p id="labelLeft">LLaMA3.1-8B + SayCan</p>
          <select id="selectLeft" style="width: 100%;"></select>
      </div>
      <div style="width: 500px; text-align: center;">
          <img id="imgRight" src="media/success-rate-heatmap_Model__GPT-4o-mini__Framework__SayCan.jpg" width="100%">
          <p id="labelRight">GPT-4o-mini + SayCan</p>
          <select id="selectRight" style="width: 100%;"></select>
      </div>
  </div>


  <script>
      const imageList = [
          { name: "LLaMA3.1-8B + SayCan", path: "media/success-rate-heatmap_Model__LLaMA3.1-8B__Framework__SayCan.jpg" },
          { name: "GPT-4o-mini + SayCan", path: "media/success-rate-heatmap_Model__GPT-4o-mini__Framework__SayCan.jpg" },
          { name: "DeepSeekMath-7B + SayCan", path: "media/success-rate-heatmap_Model__DeepSeekMath-7B__Framework__SayCan.jpg" },
          { name: "Gemma2-9B + SayCan", path: "media/success-rate-heatmap_Model__Gemma2-9B__Framework__SayCan.jpg" },
          { name: "Ministral-8B + SayCan", path: "media/success-rate-heatmap_Model__Ministral-8B__Framework__SayCan.jpg" },
          { name: "Qwen2.5-7B + SayCan", path: "media/success-rate-heatmap_Model__Qwen2.5-7B__Framework__SayCan.jpg" },
          { name: "LLaMA3.1-8B + LLM+P", path: "media/success-rate-heatmap_Model__LLaMA3.1-8B__Framework__LLM+P.jpg" },
          { name: "GPT-4o-mini + LLM+P", path: "media/success-rate-heatmap_Model__GPT-4o-mini__Framework__LLM+P.jpg" },
          { name: "DeepSeekMath-7B + LLM+P", path: "media/success-rate-heatmap_Model__DeepSeekMath-7B__Framework__LLM+P.jpg" },
          { name: "Gemma2-9B + LLM+P", path: "media/success-rate-heatmap_Model__Gemma2-9B__Framework__LLM+P.jpg" },
          { name: "Ministral-8B + LLM+P", path: "media/success-rate-heatmap_Model__Ministral-8B__Framework__LLM+P.jpg" },
          { name: "Qwen2.5-7B + LLM+P", path: "media/success-rate-heatmap_Model__Qwen2.5-7B__Framework__LLM+P.jpg" },
      ];

      const selectLeft = document.getElementById("selectLeft");
      const selectRight = document.getElementById("selectRight");
      const imgLeft = document.getElementById("imgLeft");
      const imgRight = document.getElementById("imgRight");
      const labelLeft = document.getElementById("labelLeft");
      const labelRight = document.getElementById("labelRight");

      imageList.forEach((item, index) => {
          const optionL = new Option(item.name, index);
          const optionR = new Option(item.name, index);
          selectLeft.add(optionL);
          selectRight.add(optionR);
      });

      selectLeft.selectedIndex = 0;
      selectRight.selectedIndex = 1;

      function updateImagesBenchmark() {
          const indexLeft = parseInt(selectLeft.value);
          const indexRight = parseInt(selectRight.value);
          imgLeft.src = imageList[indexLeft].path;
          labelLeft.textContent = imageList[indexLeft].name;

          imgRight.src = imageList[indexRight].path;
          labelRight.textContent = imageList[indexRight].name;
      }

      selectLeft.addEventListener("change", updateImagesBenchmark);
      selectRight.addEventListener("change", updateImagesBenchmark);
  </script>
  <!-- <img src="media\figure_case.png" alt="Teaser Image" /> -->

  <h3>Prompting Method</h3>
  <p class="text-default">
    We evaluate two novel NLP methods: the aware prompt (AP), which explicitly adds one guidance prompt to indicate possible REs, 
    and Chain-of-Thought (CoT), which guides the planner to resolve REs step by step before planning. 
    However, AP tells the planner to resolve REs even when none exist, so it fabricates references and hallucinates, 
    while CoT significantly increases response time to planners.
    To this end, we propose a simple yet effective method, task-oriented context cognition (TOCC), 
    which prompts the planner to resolve the implicit REs in the instruction and rephrase it to a more concise and straightforward one. 
  </p>
  <img src="media\figure-promptingMethod.png" alt="Teaser Image" />
  <p class="text-default">
    Among the three prompting methods compared, TOCC achieves the best performance by separating implicit RE resolution 
    from task planning and providing clearer instructions. 
  </p>
  <div class="image-display-prompting" style="display: flex; justify-content: center; gap: 20px; flex-wrap: wrap;">
      <div style="width: 700px; text-align: center;">
          <img id="imgPrompting" src="media/fig2_gemma.png" style="display: block; margin: 0 auto;">s
          <p id="labelPrompting" style="text-align: center;">LLaMA3.1-8B + SayCan</p>
          <select id="selectPrompting" style="width: 700px;"></select>
      </div>
  </div>

  <script>
    const prompting_imageList = [
        { name: "LLaMA3.1-8B + SayCan", path: "media/fig1_llama.png" },
        { name: "DeepSeekMath-7B + SayCan", path: "media/fig3_deepseek.png" },
        { name: "Gemma2-9B + SayCan", path: "media/fig2_gemma.png" },
        { name: "Ministral-8B + SayCan", path: "media/fig4_ministral.png" },
        { name: "Qwen2.5-7B + SayCan", path: "media/fig5_qwen.png" }
    ];

    const selectPrompting = document.getElementById("selectPrompting");
    const imgPrompting = document.getElementById("imgPrompting");
    const labelPrompting = document.getElementById("labelPrompting");

    prompting_imageList.forEach((item, index) => {
        const option = new Option(item.name, index);
        selectPrompting.add(option);
    });

    selectPrompting.selectedIndex = 0;

    function updateImagesPrompting() {
        const indexPrompting = parseInt(selectPrompting.value);
        imgPrompting.src = prompting_imageList[indexPrompting].path;
        labelPrompting.textContent = prompting_imageList[indexPrompting].name;
    }

    selectPrompting.addEventListener("change", updateImagesPrompting);
  </script>
  <!-- 相关研究 -->
  <h2>Related works</h2>
  <ul style="text-align: left;">
    <li>
      Jae-Woo Choi, Youngwoo Yoon, Hyobin Ong, Jaehong Kim, Minsu Jang. 
      <a href="https://arxiv.org/pdf/2402.08178" target="_blank" style="text-decoration: none; color: #2c7edb; font-weight: 500;">
        Lota-bench: Benchmarking language-oriented task planners for embodied agents
      </a>. International Conference on Learning Representations, 2024.
    </li>
    <li>
      SC Levinson. 
      <a href="https://books.google.com/books?id=SJXr9w_lVLUC" target="_blank" style="text-decoration: none; color: #2c7edb; font-weight: 500;">
        Pragmatics
      </a>. Cambridge university press, 1983.
    </li>
  </ul>

  <h2 id="bibtex" style="color: #2c7edb; font-family: sans-serif;">BibTeX</h2>
  <pre style="
      background-color: #f7f7f7;
      padding: 1em;
      font-family: monospace;
      font-size: 0.1em;
      line-height: 1.4;
      white-space: pre-wrap;
      text-align: left;
      border-radius: 8px;
      overflow-x: auto;">
      
    @article{jiang2025rei,
    title={REI-Bench: Can Embodied Agents Understand Vague Human Instructions in Task Planning?},
    author={Jiang, Chenxi and Zhou, Chuhao and Yang, Jianfei},
    journal={arXiv preprint arXiv:2505.10872},
    year={2025}
  }
  </pre>


  </div> <!-- 结束 .container -->
</body>
</html>
